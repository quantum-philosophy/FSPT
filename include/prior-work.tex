The present work is tightly related to simulation techniques. For our purposes,
it is sufficient to distinguish three types of simulators: performance, power,
and temperature. The subjects of the last two are apparent, and
\emph{performance} refers (in the scope of this paper) to everything that is
prior to power, which is essentially performance counters as functions of time,
including the numbers of instructions and read/write memory accesses.

A performance simulator that we would like to highlight is Sniper
\cite{carlson2011}. Sniper is aimed at x86-based systems, and it has been
validated against Intel Core 2 and Nehalem architectures. The simulator works at
a higher level of abstraction than the one of traditional cycle-accurate
simulators, which makes its simulation times more affordable. Regarding power
simulation, a common choice is \sc{McPAT} \cite{li2009}. \sc{McPAT} is also
capable of estimating the areas occupied by processing elements, which is handy
as this information is essential for temperature simulation. Architecture-level
temperature simulation is arguably dominated by HotSpot \cite{skadron2004}. A
popular alternative is \sc{3D-ICE} \cite{sridhar2010}, which is more focused on
\sc{3D} structures and features the modeling of inter-tier microchannel liquid
cooling.

The pipeline assembled from the aforementioned simulators is the one frequently
used today in research as the components are the state-of-the-art. However, the
pipeline as such is slow and stiff for machine-learning purposes. According to
our experience, this is mainly due to the performance-simulation and, to a
lesser extent, power-simulation components, which are considerably time
consuming. Temperature simulation, on the other hand, has a small cost compared
to the other two.

Lastly, we would like to emphasize that the need for a systematic assistance in
obtaining data for learning-based research studies, which is the goal of this
work, is prominent in the literature. For instance, the study in \cite{lu2015}
proposes a temperature-aware task-allocation strategy based on reinforcement
learning. The authors of that work had to invest time into developing a custom
simulation platform (still based on the above-mentioned simulators) in order to
experiment with their approach. From our perspective, such auxiliary work should
be streamlined.
