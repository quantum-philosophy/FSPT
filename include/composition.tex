As a result of the previous two subsections, we have obtained a stream of jobs.
This streams needs to be processed, which is the topic of this subsection. Here,
\emph{processing} refers to progressively building a schedule,\footnote{In this
paper, the mapping of tasks to processing elements is assumed to be a part of
the scheduling procedure.} constructing a power profile, and computing the
corresponding temperature profile. In \fref{methodology}, this functionality
resides in the box labeled ``Streamer.''

As motivated in \sref{motivation}, a prominent use case of our methodology is
the development of management strategies, which will be detailed further in
\sref{usage-schemes}. Therefore, the management strategy (including the
scheduling policy) of the system at hand is devised by the user. Hence, a
scheduling policy is assumed to be given. The polity decides on a schedule;
namely, for each arrived job, the policy specifies when the job gets access to
certain resources (processing elements).

Once the job has been scheduled, we proceed to updating the power profile of the
system in order to account for this scheduling decision. The power profile is
essentially a matrix that specifies the power consumption of the processing
elements over discrete time moments. The workload pattern of the job can also be
seen as such a matrix but smaller (with respect to both dimensions). For the
sake of concreteness, assume that the rows and columns of the aforementioned
matrices traverse the processing elements and time moments, respectively.

In accordance with the scheduling decision, we distribute the workload pattern
(a small matrix) of the job across the power profile (a big matrix) of the
system. This means that we place each row of the workload pattern---which
represents a power trace of a single processing element---to an appropriate row
of the power profile starting from an appropriate column. The target column
stays the same for all the rows of the workload pattern since the rows
correspond to the same time span.

There are several aspects that are worth noting. First, as mentioned in
\sref{workload}, we record dynamic and static power separately. We then make
sure that the static component is present even when no job is being
``executed.'' Second, the types of the processing elements that the workload
pattern was recorded on should be respected when scheduling and distributing the
pattern. This ensures that, for instance, the power consumption of a core does
not end up being assigned to a cache. Third, certain processing elements might
be shared across several jobs. This scenario should be treated adequately, and
we would like to elaborate on it in what follows.

The jobs that are mapped by the scheduling policy to disjoint sets of processing
elements require no special treatment. The interleaving of several jobs on a
core can be modeled by an appropriate interleaving of the corresponding workload
patterns. More concretely, workload patterns have the notion of time, and they
can be cut into pieces and stitched back as needed. This approach is well suited
for modeling preemption of low-priority jobs by higher-priority ones. Further,
even when jobs do not share cores, the corresponding cores might share caches.
Since the power consumption of caches is relatively low, an additive power model
is generally sufficient: the power values pertaining to the cache as captured by
the workload patterns of the jobs in question can be summed up to emulate the
joint effect of the jobs on the cache. Other effects originating from resource
sharing are not currently addressed by the proposed methodology and are a part
of future work.

Having discussed the construction of the power pattern, there is only one step
left. As the time goes by, we feed the power profile to a temperature simulator
and obtain a temperature profile. The obtained power and temperature profiles
are the final output of our methodology. The key observation to be made is that
no expensive performance or power simulations are involved in the data-synthesis
stage. The time consumed by the procedure delineated above is practically
negligible.
