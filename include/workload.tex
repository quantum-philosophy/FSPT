An arrival is only a time stamp without any information about the actual
workload. In this subsection, we describe how workload candidates are obtained
and complement job arrivals, which is depicted at the bottom of
\fref{methodology}. To begin with, workload candidates should conform to a
number of criteria. First, since we aim to produce realistic trace, workloads
should represent well the applications or services that the system is supposed
to provide to the user. Second, a workload should be fast to evaluate, which, in
our context, refers to obtaining the power consumption over time of that
workload.

Our workload modeling is based on full-system simulations of reference programs.
However, if we had incorporated such simulations into our workflow
\emph{directly}, we would have ended up with a configuration similar to the one
displayed in \fref{development}. This would have defeated the purpose of our
work since, as motivated in \sref{introduction}, detailed simulations are too
time consuming. Instead, we utilize high-level recordings; this functionality
corresponds to the modules labeled ``Recorder'' in \fref{methodology}. To
elaborate, using a simulator capable of modeling the target architecture, we
execute each reference program in isolation and record certain information about
this execution. At a later stage of our pipeline (see the Streamer module in
\fref{methodology}), the collected information is utilized in order to flesh out
jobs upon their arrival, and this stage requires no simulation.

Performance and power simulation takes by far the largest expense in terms of
time. Therefore, the information about a reference program's execution that we
record is the power consumption of that execution. This approach pushes the
aforementioned expense to the data-acquisition stage and eliminates it from the
data-synthesis stage. Since the actual data generation is deliver from the
expensive simulations, it has a very low computational demand. This demand is
negligible compared to the one of the scenario depicted in \fref{development},
in which one undertakes performance and power simulations nonstop.

The power consumption of a program can be recorded in different ways. The first
aspect to note is that we record power as a function of time (assuming a certain
sampling interval). Second, the dynamic and static components of the power
consumption are recorded separately for a better control over the subsequent
composition (\sref{composition}). Third, the power consumption is recorded for
all the processing elements of interest (for instance, cores and shared caches).

The result of recording is a repository of power traces corresponding to real
programs, which we refer to as workload patterns; see the bottom cloud in
\fref{methodology}. Full-system simulations take time; however, they have to be
done only once.

Regarding the assignment of a workload pattern to an arrival, we shall refer to
this functionality as the workload model. The input to this model is a stream of
arrival times, and its output is a stream of fully characterized jobs (time and
work). The workload model relies on domain-specific knowledge. For instance, the
output stream can be made dependent on the input one in order to introduce
autocorrelations and, thereby, model periodic and coupled workloads. Therefore,
we let the model be user defined. The default option that is used in our
toolchain is choosing workload patterns at random.

To recapitulate, we have obtained a database of reference workloads and
discussed the formation of job streams from arrival streams. The utilized
patterns correspond to executions of real programs and, thus, exhibit realistic
traits.
