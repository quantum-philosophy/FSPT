\input{include/assets/figures/workload}
In the previous subsection, we introduced our approach to generating streams of
arrivals; however, an arrival is only a time stamp without any information about
the actual workload. In this subsection, we describe how workloads needed for
substantiating job arrivals are obtained, which is depicted in the bottom part
of \fref{methodology}. To begin with, workload candidates should conform to a
number of criteria. First, as emphasized throughout the paper, we aim to produce
realistic power and temperature traces, and, therefore, workloads should
represent well the applications or services that the system in question is
supposed to provide to the end user. Second, a workload should be fast to
evaluate, which, in our context, refers to computing the power consumption of
that workload.

The particularities of the power consumption of a computer program are hard to
fabricate. A sequence of random numbers taken out of thin air will not do the
trick as programs have certain algorithmic structures.
Figure~\ref{fig:workload} illustrates the power consumption of four applications
taken from the \sc{SPEC CPU2006} benchmark suite \cite{cpu2006}. A program
might, for instance, traverse a number of phases, and each phase might trigger a
number of distinctive computations, shaping the corresponding power and
temperature profiles. Such features are important to preserve in order to make
the subsequent experimentation with machine-learning techniques and alike
meaningful.

With the above concern in mind, the workload-modeling part of our methodology is
based on full-system simulations of reference programs. However, if we had
incorporated such simulations directly into our workflow, it would have defeated
the purpose of our work since, as motivated in \sref{motivation}, detailed
simulations are too time consuming. Instead, we propose the use of high-level
recordings; see the box labeled ``Recorder'' in \fref{methodology}. To
elaborate, using an adequate simulator capable of modeling the target
architecture, we execute each reference program and record certain information
about this execution.\footnote{Such a technique is similar in spirit to PinPlay
\cite{patil2010}, which is a tool for recording and replaying an execution of a
program on the instruction level.} At a later stage of our pipeline (the box
labeled ``Streamer''), the collected information is utilized in order to flesh
out jobs upon their arrival, and this stage requires no simulation.

From our experience, performance and power simulation is by far the largest
expense on the way to temperature, and, therefore, we propose to record power
directly, eliminating this expense all together. Then the result of the
procedure described above is a repository of power traces corresponding to real
programs, which we refer to as workload patterns (see \fref{methodology}). These
patterns are building blocks: they are used to construct a power profile of the
system under consideration, which we further elaborate on in the next
subsection, \sref{composition}.

Full-system simulations obviously take time; however, they should be done only
once. Moreover, since researchers tend to test their ideas using similar sets of
benchmark suites and considering similar sets of target architectures, it makes
sense to create a common repository of power patterns that will be populated and
maintained online by the research community. In this case, power patterns will
be at a one-click distance from any single researcher, and no prior simulation
will be needed. The role of such a repository could be similar to the one played
nowadays by the benchmark suites themselves, but it would be on a different
level and for a different purpose.

Let us now turn to the question: How do we choose which workload pattern to use
for a particular arrival? First of all, since arrivals are modeled as a stream,
it is convenient to turn workloads into a stream as well so that we can draw an
element from each stream and obtain a fully characterized job (time and
payload). Then the question boils down to the logic behind the workload stream.
The workload stream can be dependent on the arrival stream, which allows for
modeling, for instance, periodic workloads. The workload stream can also be
autocorrelated, which allows for modeling, for instance, paired workloads. Since
such aspects rely heavily on domain-specific knowledge, we refrain from
providing any particular dependency model. The default option used in our
toolchain, which is to be discussed in \sref{toolchain}, is drawing samples from
a uniform distribution over a set of workload patterns.

The stream abstraction introduced in the previous paragraph also helps to
communicate the notion of workload transformation. A workload transformation is
an optional means of workload diversification. A selected workload pattern can
pass through a number of filters---such as noise, offset, scale, stretch, and
shrink---before being pulled from the stream. This, however, should be done
thoughtfully as the purpose of recording power patterns is in part to bring in
realistic power fluctuations.

To recapitulate, we have obtained a database of reference workloads and
discussed the formation of workload streams, which complement arrival streams.
The workload patterns correspond to executions of real programs and, therefore,
exhibit the particularities found in real life.
